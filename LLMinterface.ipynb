{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.DbLoadUtils import getMongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MongoDB successful\n"
     ]
    }
   ],
   "source": [
    "uri = \"mongodb+srv://admin:admin@bigdata.em7viry.mongodb.net/?retryWrites=true&w=majority&appName=BigData\"\n",
    "mongoClient = getMongoClient(uri)\n",
    "\n",
    "db = mongoClient[\"BigDataProj\"]\n",
    "collection = db[\"BigDataProj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Nico\\Documenti\\GitHub\\Big-Data\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\Nico\\Documenti\\GitHub\\Big-Data\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "vectorStore = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    uri,\n",
    "    db.name + \".\" + collection.name,\n",
    "    embedding_model,\n",
    "    relevance_score_fn = \"cosine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc608f0d28c40b7b4f02bb80c48d463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "modelName = \"osiria/diablo-italian-base-1.3b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(modelName, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.embed_query(text)\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(user_query, collection):\n",
    "    \"\"\"\n",
    "    Perform a vector search in the MongoDB collection based on the user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "    collection (MongoCollection): The MongoDB collection to search.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of matching documents.\n",
    "    \"\"\"\n",
    "\n",
    "    query_embedding = get_embedding(user_query)\n",
    "\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "\n",
    "\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"default\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"embedding\",\n",
    "                \"numCandidates\": 10000,  \n",
    "                \"limit\": 5,  \n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,  \n",
    "                \"utente\": 1,  \n",
    "                \"titolo\": 1,  \n",
    "                \"dottore\": 1,  \n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},  \n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrompt(query: str):\n",
    "    \n",
    "    docs = vector_search(query, collection=collection)\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += doc[\"dottore\"].strip() + \"\\n\"\n",
    "        \n",
    "    istruction = \"\"\"Sei un dottore che deve rispondere alle domande di un paziente. Unisci la tua conoscenza pregressa a queste risposte fornite da medici ad altri pazienti con problemi simili ma non citarle direttamente. \n",
    "Non inventare e se non conosci la riposta suggerisci un consulto medico. Genera una risposta rapida e concisa, senza ripetizioni. Usa un tono professionale e senza errori grammaticali. Indica unicamente la riposta alla domanda.\n",
    "Non rispondere con il tuo nome e non identificarti. Elenca delle possibili soluzione.\"\"\"\n",
    "    \n",
    "    return f\"\"\"CONTESTO: {context}\n",
    "DOMANDA: {query}\n",
    "ISTRUZIONI: {istruction}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Ciao, ho mal di testa. Cosa posso fare?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "hf = HuggingFaceHub(\n",
    "    repo_id=\"google/gemma-1.1-7b-it\",\n",
    "    model_kwargs={\"temperature\":0.1, \"max_length\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt  = createPrompt(query)\n",
    "response = hf.generate([prompt], max_new_tokens=300, do_sample = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=\"CONTESTO: BENSIDovresti raccontarmi di piu sul tuo mal di testa. In particolare se vi è anche dolore cervicale,             se si accompagna a trafitte,             se è a peso o a stretta,             se è solo da un lato,             se hai fastidio ad appoggiare la testa sul cuscino,             se ti fa male la cute,             insomma il cuoio capelluto,           ,             se questo mal di testa si accentua o si scatena  con gli sforzi. . Con quale frequenza ne soffri in un mese. Se riesci a dirmi piu cose possibili  proverò ad aiutarti. Dott. Alessandro Bensi Specialista attività privata\\nGentile Utente, a parte alternare periodi di assunzione e periodi di riposo, sarebbe anche da prendere in considerazione l'uso di altre molecole di prevenzione, ne esistono tante, ovviamente deve essere il neurologo a prescriverle. Perchè non parla di questa ipotesi con lo specialista? Cordiali saluti Dr. Antonio Ferraloro\\nLA SUA EMICRANIA INTERPRETATA SECONDO LA MEDICINA CINESE E' LEGATA AL FUOCO DEL FEGATO. PUO' ESSERE CURATA CON L'AGOPUNTURA. Dr.\\xa0SALVATORE\\xa0TOMASONE\\nEMILIO QUISISI RIVOLGA AD UN NEUROLOGO DI FIDUCIA,             ESPERTO DI CEFALEE,             PER AVERE INDICAZIONI SPECIFICHE Dott. QUIRINO EMILIO QUISI Specialista attività privataUniversitarioSpecialista in Medicina dello sportSpecialista in PsichiatriaBusto Arsizio (VA)\\nEMILIO QUISIsegua,             gentilissima,             l'ipotesi della tac cerebri,             prescritta dal suo medico e con questa torni in p.             soccorso. per la sua parestesia,             atenderei un attimo prima di dire che è solo Ansia. Dott. QUIRINO EMILIO QUISI Specialista attività privataUniversitarioSpecialista in Medicina dello sportSpecialista in PsichiatriaBusto Arsizio (VA)\\n\\nDOMANDA: Ciao, ho mal di testa. Cosa posso fare?\\nISTRUZIONI: Sei un dottore che deve rispondere alle domande di un paziente. Unisci la tua conoscenza pregressa a queste risposte fornite da medici ad altri pazienti con problemi simili ma non citarle direttamente. \\nNon inventare e se non conosci la riposta suggerisci un consulto medico. Genera una risposta rapida e concisa, senza ripetizioni. Usa un tono professionale e senza errori grammaticali. Indica unicamente la riposta alla domanda.\\nNon rispondere con il tuo nome e non identificarti. Elenca delle possibili soluzione.\\n**Risposta:**\\n\\nPotresti provare un'agopuntura per la migrena o un trattamento medico specifico prescrito da un neurologo.\")]], llm_output=None, run=[RunInfo(run_id=UUID('ad1efe83-3a4a-4fdf-9cba-b98ccb8c9cac'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

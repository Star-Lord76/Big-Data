{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.DbLoadUtils import getMongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"mongodb+srv://admin:admin@bigdata.em7viry.mongodb.net/?retryWrites=true&w=majority&appName=BigData\"\n",
    "mongoClient = getMongoClient(uri)\n",
    "\n",
    "db = mongoClient[\"BigData\"]\n",
    "collection = db[\"MedicalLLM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "vectorStore = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    uri,\n",
    "    db.name + \".\" + collection.name,\n",
    "    embedding_model,\n",
    "    relevance_score_fn = \"cosine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "modelName = \"google/gemma-1.1-7b-it\"\n",
    "\n",
    "hf = HuggingFaceHub(\n",
    "    repo_id=modelName,\n",
    "    model_kwargs={\"temperature\":0.5, \"max_length\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.embed_query(text)\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(user_query, collection, sito=None):\n",
    "    \"\"\"\n",
    "    Perform a vector search in the MongoDB collection based on the user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "    collection (MongoCollection): The MongoDB collection to search.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of matching documents.\n",
    "    \"\"\"\n",
    "\n",
    "    query_embedding = get_embedding(user_query)\n",
    "\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "\n",
    "\n",
    "    pipeline = [\n",
    "    {\n",
    "        \"$vectorSearch\": {\n",
    "            \"index\": \"vector_index\",\n",
    "            \"queryVector\": query_embedding,\n",
    "            \"path\": \"embedding\",\n",
    "            \"numCandidates\": 5000,\n",
    "            \"limit\": 10\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"sito\": 1,\n",
    "            \"dottore\": 1,\n",
    "            \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "        }\n",
    "    }\n",
    "];\n",
    "\n",
    "    if sito:\n",
    "        pipeline.append( {\n",
    "        \"$match\": {\n",
    "            \"sito\": sito\n",
    "        }\n",
    "    })\n",
    "\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import json_util\n",
    "import json\n",
    "\n",
    "def create_time_series(collection):\n",
    "    pipeline = [\n",
    "        {\n",
    "            # Convert the date string to a date object and extract the year and month\n",
    "            \"$project\": {\n",
    "                \"sito\": 1,\n",
    "                \"yearMonth\": {\n",
    "                    \"$dateToString\": {\n",
    "                        \"format\": \"%Y-%m\",\n",
    "                        \"date\": {\"$dateFromString\": {\"dateString\": \"$data\"}}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            # Group by sito and year-month\n",
    "            \"$group\": {\n",
    "                \"_id\": {\n",
    "                    \"sito\": \"$sito\",\n",
    "                    \"yearMonth\": \"$yearMonth\"\n",
    "                },\n",
    "                \"count\": {\"$sum\": 1}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            # Sort by sito and year-month\n",
    "            \"$sort\": {\n",
    "                \"_id.sito\": 1,\n",
    "                \"_id.yearMonth\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            # Reshape the documents to have sito as the main document with counts per month\n",
    "            \"$group\": {\n",
    "                \"_id\": \"$_id.sito\",\n",
    "                \"counts\": {\n",
    "                    \"$push\": {\n",
    "                        \"month\": \"$_id.yearMonth\",\n",
    "                        \"count\": \"$count\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            # Sort the results by sito\n",
    "            \"$sort\": {\"_id\": 1}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = collection.aggregate(pipeline)\n",
    "    # Convert the aggregation cursor to a list of dictionaries\n",
    "    return json.loads(json_util.dumps(results))\n",
    "\n",
    "# Call the function with your collection\n",
    "# print(create_time_series(your_collection))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCount(collection) -> dict:\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": \"$sito\",  # Use \"$sito\" to reference the field name\n",
    "                \"count\": {\"$sum\": 1}  # Correct the syntax for $sum\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$sort\": {\"count\": -1}  # Correct the syntax for $sort\n",
    "        }\n",
    "    ]\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return {result['_id']: result['count'] for result in results}  # Convert cursor to dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_time_series(collection)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search(\"Ciao, cosa devo fare per capire se sono celiaco?\", collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrompt(query: str, site=None):\n",
    "    \n",
    "    docs = vector_search(query, collection, site)\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += doc[\"dottore\"].strip() + \"\\n\\n\"\n",
    "        \n",
    "    istruction = \"\"\"Sei un dottore che deve rispondere alle domande di un paziente. Unisci la tua conoscenza pregressa a queste risposte fornite da medici ad altri pazienti con problemi simili ma non citarle direttamente. \n",
    "Non inventare. Genera una risposta rapida e concisa, senza ripetizioni. Usa un tono professionale e senza errori grammaticali. Indica unicamente la riposta alla domanda.\n",
    "Non rispondere con il tuo nome e non identificarti. Elenca delle possibili soluzione.\"\"\"\n",
    "    \n",
    "    return f\"\"\"CONTESTO: {context}\n",
    "DOMANDA: {query}\n",
    "ISTRUZIONI: {istruction}\n",
    "RISPOSTA:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global variable\n",
    "global_variable = \"Entrambi\"\n",
    "# Function to update the global variable based on the dropdown selection\n",
    "def update_global_variable(selection):\n",
    "    global global_variable\n",
    "    global_variable = selection\n",
    "    return f\"Global variable updated to: {global_variable}\"\n",
    "\n",
    "def answer(query: str, site = None):\n",
    "    if site != \"Dire\" and site != \"Medic\":\n",
    "        site = None\n",
    "    prompt  = createPrompt(query, site)\n",
    "    response = hf.generate([prompt], max_new_tokens=1000, do_sample = True)\n",
    "    splitted = response.generations[0][0].text.split(\"RISPOSTA:\")[-1]\n",
    "    return splitted.strip()\n",
    "\n",
    "\n",
    "def answerNoRag(query: str):\n",
    "    response = hf.generate([query], max_new_tokens=1000, do_sample = True)\n",
    "    splitted = response.generations[0][0].text\n",
    "    return splitted.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_time_series(results):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "    for site_data in results:\n",
    "        site = site_data['_id']\n",
    "        counts = site_data['counts']\n",
    "        \n",
    "        dates = [datetime.strptime(month_count['month'], '%Y-%m') for month_count in counts]\n",
    "        values = [month_count['count'] for month_count in counts]\n",
    "        \n",
    "        ax.plot(dates, values, marker='o', label=site)  # Adjust marker style and size as needed\n",
    "\n",
    "    # Improve the x-axis labels\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))  # Show a label every month\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n",
    "\n",
    "    # Add grid lines\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Month', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.set_title('Time Series of Counts by Site', fontsize=14)\n",
    "\n",
    "    # Add a legend\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=10))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()  # Adjust the layout to fit all elements\n",
    "    return fig\n",
    "\n",
    "def plot():\n",
    "    return plot_time_series(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    with gr.Row():\n",
    "        \n",
    "        with gr.Column():\n",
    "            inputs=gr.Dropdown(choices=['Medic', 'Dire', \"Entrambi\"], label=\"Seleziona un sito di origine\")\n",
    "        with gr.Column():\n",
    "            input_text = gr.Textbox(label=\"Enter a question\")\n",
    "            output_text = gr.Textbox(label=\"Output\")\n",
    "            button_compute = gr.Button(\"Compute\")\n",
    "            button_compute.click(answer, inputs=[input_text, inputs], outputs=output_text)\n",
    "            \n",
    "    with gr.Row():\n",
    "        plot_component = gr.Plot()\n",
    "        button_plot = gr.Button(\"Generate Plot\")\n",
    "        button_plot.click(plot, outputs=plot_component)\n",
    "    \n",
    "    \n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

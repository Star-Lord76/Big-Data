{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.DbLoadUtils import getMongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MongoDB successful\n"
     ]
    }
   ],
   "source": [
    "uri = \"mongodb+srv://admin:admin@bigdata.em7viry.mongodb.net/?retryWrites=true&w=majority&appName=BigData\"\n",
    "mongoClient = getMongoClient(uri)\n",
    "\n",
    "db = mongoClient[\"BigDataProjPoc\"]\n",
    "collection = db[\"BigDataProjPoc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Nico\\Documenti\\GitHub\\Big-Data\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\Nico\\Documenti\\GitHub\\Big-Data\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "\n",
    "vectorStore = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    uri,\n",
    "    db.name + \".\" + collection.name,\n",
    "    embedding_model,\n",
    "    relevance_score_fn = \"cosine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbdaed5d50c4db4b4712ff7353edff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "modelName = \"google/gemma-1.1-7b-it\"\n",
    "\n",
    "hf2 = HuggingFaceHub(\n",
    "    repo_id=modelName,\n",
    "    model_kwargs={\"temperature\":0.1, \"max_length\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str) -> list[float]:\n",
    "    if not text.strip():\n",
    "        print(\"Attempted to get embedding for empty text.\")\n",
    "        return []\n",
    "\n",
    "    embedding = embedding_model.embed_query(text)\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(sintomi, collection):\n",
    "    sintomi_embedding = get_embedding(sintomi)\n",
    "\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"vector_index\",\n",
    "                \"queryVector\": sintomi_embedding,\n",
    "                \"path\": \"embedding\",\n",
    "                \"numCandidates\": 10000,\n",
    "                \"limit\": 10,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"Sintomi e motivi della domanda\": 1,\n",
    "                \"Note sul paziente\": 1,\n",
    "                \"Medicinali consigliati\": 1,\n",
    "                \"Esami Consigliati\": 1,\n",
    "                \"Considerazioni del Medico e Note\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPromptForGeneration(query: str):\n",
    "    \n",
    "    docs = vector_search(query, collection=collection)\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += str(doc[\"Medicinali consigliati\"]).strip() + \"\\n\"\n",
    "        context += str(doc[\"Considerazioni del Medico e Note\"]).strip() + \"\\n\\n\"\n",
    "        \n",
    "    instruction = \"\"\"Sei un dottore che deve formulare una possibile cure per i sintomi rilevati. Unisci la tua conoscenza pregressa ai dati forniti dal contesto. \n",
    "Non inventare. Genera una risposta rapida e concisa, senza ripetizioni. Usa un tono professionale e senza errori grammaticali. Indica unicamente la riposta alla domanda.\n",
    "Non rispondere con il tuo nome e non identificarti. Elenca delle possibili soluzione.\"\"\"\n",
    "    \n",
    "    return f\"\"\"CONTESTO: {context}\n",
    "SINTOMI RILEVATI: {query}\n",
    "ISTRUZIONI: {instruction}\n",
    "RISPOSTA:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPromptForExtraction(text: str):\n",
    "    instruction =\"Estrai i sintomi e le motivazioni dalla seguente domanda: \"\n",
    "    return instruction + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "modelName = \"google/gemma-1.1-7b-it\"\n",
    "\n",
    "hf1 = HuggingFaceHub(\n",
    "    repo_id=modelName,\n",
    "    model_kwargs={\"max_length\":500})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(query: str):\n",
    "    \n",
    "    extraction = createPromptForExtraction(query)\n",
    "    response = hf1.generate([extraction], max_new_tokens=1000)\n",
    "    splitted = response.generations[0][0].text\n",
    "    \n",
    "    \n",
    "    \n",
    "    prompt  = createPromptForGeneration(splitted)\n",
    "    print(prompt)\n",
    "    response = hf2.generate([prompt], max_new_tokens=1000, do_sample = True)\n",
    "    splitted = response.generations[0][0].text.split(\"RISPOSTA:\")[-1]\n",
    "    return splitted.strip()\n",
    "\n",
    "\n",
    "def answerNoRag(query: str):\n",
    "    response = hf2.generate([query], max_new_tokens=1000, do_sample = True)\n",
    "    splitted = response.generations[0][0].text\n",
    "    return splitted.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer(\"Ciao, cosa devo fare per capire se sono celiaco?\"))\n",
    "print(answerNoRag(\"Ciao, cosa devo fare per capire se sono celiaco?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTESTO: ['Adepril', 'Tramadolo']\n",
      "[\"Lo Zomig non è incompatibile con l'Adepril.\", 'La dose minima di Adepril è di 10 mg e la sua assunzione con Tramadolo dovrebbe essere strettamente monitorata da un neurologo qualificato.']\n",
      "\n",
      "nan\n",
      "[\"Le aree di gliosi encefalica possono essere associati ad una varietà di problemi, tra cui l'emicrania con aura.\", 'Il stress e il caldo eccessivo possono influenzare la frequenza e la gravità degli attacchi. ', 'È importante indagare la causa delle aree di gliosi encefalica e della frequenza degli attacchi.']\n",
      "\n",
      "nan\n",
      "['La posizione distesa potrebbe essere un fattore aggravante della cefalea.', \"Una terapia farmacologica di prevenzione potrebbe essere la scelta di elezione per evitare l'abuso di analgesici e la cronicizzazione della cefalea.\"]\n",
      "\n",
      "[\"Continua l'uso delle lenti\", 'Provare a abituarsi ai nuovi occhiali', 'Verificare la corretta gradazione degli occhiali']\n",
      "[\"Abituarsi all'astigmatismo non è sempre facile e richiede tempo e impegno.\", \"È importante verificare se la gradazione degli occhiali sia stata correttamente effettuata e se l'asse sia stato rispettato.\"]\n",
      "\n",
      "['Nessun farmaco specifico viene consigliato']\n",
      "['La celiachia è una possibile diagnosi in base ai sintomi del paziente.', 'La diagnosi definitiva dovrebbe essere effettuata da un gastroenterologo esperto in celiachia.', \"L'unico trattamento possibile per la celiachia è l'eliminazione definitiva e permanente di tutti i prodotti contenenti glutine.\"]\n",
      "\n",
      "['Non viene fornito alcuna informazione aggiuntiva sul farmaco consigliato.']\n",
      "['Non viene fornito alcuna informazione aggiuntiva sulle considerazioni del medico o le note.']\n",
      "\n",
      "['Esame del sangue per confirmare o escludere la diagnosi.']\n",
      "['Le probabilità di diabete mellito di tipo 1 sono alte.', 'È importante monitorare la salute e non ignorare la situazione.', 'Ci sono numerose risorse disponibili online e nei centri comunità locali per aiutare a gestire la condizione.']\n",
      "\n",
      "nan\n",
      "['Il dottore ha solo fornito un feedback sulla comunicazione del paziente, non ha fornito alcuna diagnosi o trattamento.']\n",
      "\n",
      "['Yogurt live.', 'Farmaci antiacici (solo se necessario).']\n",
      "['Le sintomi descritte non hanno una correlazione con i problemi ai reni.', 'La terapia con lo yogurt live è un trattamento efficace e sicuro contro la malattia da reflusso.']\n",
      "\n",
      "nan\n",
      "[\"Si potrebbe trattare di un'emicrania atipica.\", \"È importantePerforming un'accurata valutazione del paziente al fine di discriminare tra un'emicrania e altre condizioni.\"]\n",
      "\n",
      "\n",
      "SINTOMI RILEVATI: Estrai i sintomi e le motivazioni dalla seguente domanda: Ciao, ho un fortissimo mal di testa. Ho bisogno di un medicinale per alleviare la sofferenza. Qual è il miglior medicinale per il mal di testa?\n",
      "\n",
      "**Sintomi:**\n",
      "- Mal di testa\n",
      "- Soffrire\n",
      "\n",
      "**Motivazioni:**\n",
      "- Alleviare la sofferenza del mal di testa\n",
      "\n",
      "**Nota:** non è possibile fornire suggerimenti medici o farmaceutici.\n",
      "ISTRUZIONI: Sei un dottore che deve formulare una possibile cure per i sintomi rilevati. Unisci la tua conoscenza pregressa ai dati forniti dal contesto. \n",
      "Non inventare. Genera una risposta rapida e concisa, senza ripetizioni. Usa un tono professionale e senza errori grammaticali. Indica unicamente la riposta alla domanda.\n",
      "Non rispondere con il tuo nome e non identificarti. Elenca delle possibili soluzione.\n",
      "RISPOSTA:\n",
      "\n",
      "Poiché non è stato fornito alcun farmaco specifico come trattamento, le opzioni possibili sono:\n",
      "- Farmaci antiacici (solo se necessario).\n",
      "- Yogurt live.\n",
      "- Esame del sangue per confirmare o escludere la diagnosi di un'emicrania.\n"
     ]
    }
   ],
   "source": [
    "print(answer(\"Ciao, ho un fortissimo mal di testa.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(query:str):\n",
    "    return answer(query), answerNoRag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=grad,\n",
    "    inputs=[\"text\"],\n",
    "    outputs=[\"text\", \"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
